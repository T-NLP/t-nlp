{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2682586,"sourceType":"datasetVersion","datasetId":1612507}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# Gerekli Kütüphaneler\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\n\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader, random_split\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\nfrom torch import nn\nfrom tqdm import tqdm\n\nwarnings.filterwarnings('ignore')\n\n# GPU Kontrolü\nif torch.cuda.is_available():\n    for i in range(torch.cuda.device_count()):\n        print(torch.cuda.get_device_name(i))  # GPU adlarını listeler\nelse:\n    print(\"No GPUs found\")\n\n# Veriyi Yükleme\nreviews = pd.read_csv(\"/kaggle/input/eticaret-urun-yorumlari/e-ticaret_urun_yorumlari.csv\", on_bad_lines=\"skip\", delimiter=\";\")\nprint(reviews.shape)\nprint(reviews.sample(5))\n\n# Veriyi Temizleme\nreviews.drop_duplicates(keep='first', inplace=True)\nprint(reviews.shape)\nprint(reviews['Durum'].value_counts(normalize=True, dropna=False))\n\n# Özellikler ve Etiketler\nX = reviews['Metin'].values\ny = reviews['Durum'].values\n\n# Tokenizer ve Modeli Yükleme\ncheckpoint_name = \"balciberin/distilbert_turkish_sentiment_analysis2\"  # DistilBERT modeli\ntokenizer = DistilBertTokenizer.from_pretrained(checkpoint_name)\nmodel = DistilBertForSequenceClassification.from_pretrained(checkpoint_name, num_labels=3, ignore_mismatched_sizes=True)\n\n# Tokenizasyon\ntokenized_inputs = tokenizer(X.tolist(),  \n                             padding='max_length',  \n                             truncation=True,  \n                             max_length=65,  \n                             return_tensors='pt')\n\ninput_ids = tokenized_inputs['input_ids']\nattention_mask = tokenized_inputs['attention_mask']\n\nlabels = torch.tensor(y, dtype=torch.long)\n\n# Dataset ve DataLoader\ndataset = TensorDataset(input_ids, attention_mask, labels)\n\nsplit = 0.9\ntotal_size = len(dataset)\ntrain_size = int(total_size * split)\nval_size = total_size - train_size\n\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\nbatch_size = 32\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)  # Validation için shuffle=False\n\n# Optimizasyon ve Scheduler\noptimizer = AdamW(model.parameters(), lr=2e-5)\nnum_epochs = 3\n\ntotal_steps = num_epochs * len(train_dataloader)\nwarmup_percentage = 0.1\nnum_warmup_steps = int(total_steps * warmup_percentage)\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer, \n    num_warmup_steps=num_warmup_steps, \n    num_training_steps=total_steps\n)\n\nloss_fn = nn.CrossEntropyLoss()\n\n# Eğitim Fonksiyonu\ndef train_epoch(model, train_dataloader, optimizer, loss_fn, scheduler, device, progress_bar=None):\n    model.train()\n    total_loss = 0\n    \n    for batch in train_dataloader:\n        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        total_loss += loss.item()\n\n        if progress_bar:\n            progress_bar.update(1)\n    \n    avg_loss = total_loss / len(train_dataloader)\n    return avg_loss\n\n# Değerlendirme Fonksiyonu\ndef eval_epoch(model, val_dataloader, loss_fn, device):\n    model.eval()\n    total_loss = 0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for batch in val_dataloader:\n            input_ids, attention_mask, labels = [x.to(device) for x in batch]\n            \n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            logits = outputs.logits\n\n            total_loss += loss.item()\n            preds = torch.argmax(logits, dim=1)\n            correct += (preds == labels).sum().item()\n            total += len(labels)\n\n    avg_loss = total_loss / len(val_dataloader)\n    accuracy = correct / total\n    return avg_loss, accuracy\n\n# Eğitim ve Değerlendirme\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nfor epoch in range(num_epochs):\n    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n\n    train_loss = 0\n    with tqdm(total=len(train_dataloader), desc=f\"Training Epoch {epoch + 1}\") as pbar:\n        train_loss = train_epoch(model, train_dataloader, optimizer, loss_fn, scheduler, device, pbar)\n\n    val_loss, val_accuracy = eval_epoch(model, val_dataloader, loss_fn, device)\n\n    print(f\"Training loss: {train_loss:.4f}\")\n    print(f\"Validation loss: {val_loss:.4f}, Validation accuracy: {val_accuracy:.4f}\")\n\n# Modeli Kaydetme\nmodel.save_pretrained(\"DistilBert_sentiment_Turkish_product_reviews\")\n\n# Modeli Yükleme\nmodel_loaded = DistilBertForSequenceClassification.from_pretrained(\"DistilBert_sentiment_Turkish_product_reviews\")\nmodel_loaded.to(device)\n\n# Yeni Tahminler\ndef make_new_prediction(raw_review, model):\n    tokenized_review = tokenizer(\n        raw_review,\n        return_tensors='pt', \n        padding=True,\n        truncation=True,\n        max_length=65\n    )\n    \n    input_ids = tokenized_review['input_ids'].to(device)\n    attention_mask = tokenized_review['attention_mask'].to(device)\n    \n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n    \n    predicted_class = torch.argmax(logits, dim=1).item()\n\n    class_labels = {0: 'Negative', 1: 'Positive', 2: 'Neutral'}\n    predicted_label = class_labels[predicted_class]\n\n    print(\"Predicted class for the new review:\", predicted_label)\n    \n    return predicted_label\n\n# Örnek bir inceleme\nnew_review = \"guzel bir urundu, begendim, fiyati da gayet makul.\"\nmake_new_prediction(new_review, model_loaded)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-07T19:32:15.640740Z","iopub.execute_input":"2024-08-07T19:32:15.641096Z","iopub.status.idle":"2024-08-07T19:35:46.877080Z","shell.execute_reply.started":"2024-08-07T19:32:15.641067Z","shell.execute_reply":"2024-08-07T19:35:46.876112Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Tesla T4\nTesla T4\n(15170, 2)\n                                                   Metin  Durum\n11002  çözemedik kötü geldi kullanışlı değil hiç ve s...      0\n15088  2 kullanmada patladı içi yanmış kullanamadım bile      0\n13491  O kadar kalitesiz ki kutuya bile koymaya gerek...      0\n9412          teşekürler ürün bekledigim gibi geldi ????      1\n6722   hem fiyatı hemde kalitesi süper oğlum bayıldı ...      1\n(13569, 2)\nDurum\n0    0.477854\n1    0.427003\n2    0.095143\nName: proportion, dtype: float64\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at balciberin/distilbert_turkish_sentiment_analysis2 and are newly initialized because the shapes did not match:\n- classifier.bias: found shape torch.Size([6]) in the checkpoint and torch.Size([3]) in the model instantiated\n- classifier.weight: found shape torch.Size([6, 768]) in the checkpoint and torch.Size([3, 768]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 1: 100%|██████████| 381/381 [01:01<00:00,  6.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training loss: 0.5847\nValidation loss: 0.3325, Validation accuracy: 0.8757\nEpoch 2/3\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 2: 100%|██████████| 381/381 [01:04<00:00,  5.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training loss: 0.3135\nValidation loss: 0.3120, Validation accuracy: 0.8847\nEpoch 3/3\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 3: 100%|██████████| 381/381 [01:04<00:00,  5.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training loss: 0.2488\nValidation loss: 0.2771, Validation accuracy: 0.8996\nPredicted class for the new review: Positive\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'Positive'"},"metadata":{}}]},{"cell_type":"code","source":"new_review = \"turkcellin bu hizmeti ne abi ya baya kötü\"\nmake_new_prediction(new_review, model_loaded)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T19:53:01.760935Z","iopub.execute_input":"2024-08-07T19:53:01.761534Z","iopub.status.idle":"2024-08-07T19:53:01.777473Z","shell.execute_reply.started":"2024-08-07T19:53:01.761501Z","shell.execute_reply":"2024-08-07T19:53:01.776626Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Predicted class for the new review: Negative\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'Negative'"},"metadata":{}}]}]}