{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2682586,"sourceType":"datasetVersion","datasetId":1612507}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Gerekli Kütüphaneler\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\n\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader, random_split\nfrom transformers import ElectraTokenizer, ElectraForSequenceClassification, AdamW, get_linear_schedule_with_warmup\nfrom torch import nn\nfrom tqdm import tqdm\n\nwarnings.filterwarnings('ignore')\n\n# GPU Kontrolü\nif torch.cuda.is_available():\n    for i in range(torch.cuda.device_count()):\n        print(torch.cuda.get_device_name(i))  # GPU adlarını listeler\nelse:\n    print(\"No GPUs found\")\n\n# Veriyi Yükleme\nreviews = pd.read_csv(\"/kaggle/input/eticaret-urun-yorumlari/e-ticaret_urun_yorumlari.csv\", on_bad_lines=\"skip\", delimiter=\";\")\nprint(reviews.shape)\nprint(reviews.sample(5))\n\n# Veriyi Temizleme\nreviews.drop_duplicates(keep='first', inplace=True)\nprint(reviews.shape)\nprint(reviews['Durum'].value_counts(normalize=True, dropna=False))\n\n# Özellikler ve Etiketler\nX = reviews['Metin'].values\ny = reviews['Durum'].values\n\n# Tokenizer ve Modeli Yükleme\ncheckpoint_name = \"kuzgunlar/electra-turkish-sentiment-analysis\"\ntokenizer = ElectraTokenizer.from_pretrained(checkpoint_name)\nmodel = ElectraForSequenceClassification.from_pretrained(checkpoint_name, num_labels=3, ignore_mismatched_sizes=True)\n\n# Tokenizasyon\ntokenized_inputs = tokenizer(X.tolist(),  \n                             padding='max_length',  \n                             truncation=True,  \n                             max_length=65,  \n                             return_tensors='pt')\n\ninput_ids = tokenized_inputs['input_ids']\nattention_mask = tokenized_inputs['attention_mask']\n\nlabels = torch.tensor(y, dtype=torch.long)\n\n# Dataset ve DataLoader\ndataset = TensorDataset(input_ids, attention_mask, labels)\n\nsplit = 0.9\ntotal_size = len(dataset)\ntrain_size = int(total_size * split)\nval_size = total_size - train_size\n\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\nbatch_size = 32\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n\n# Optimizasyon ve Scheduler\noptimizer = AdamW(model.parameters(), lr=2e-5)\nnum_epochs = 3\n\ntotal_steps = num_epochs * len(train_dataloader)\nwarmup_percentage = 0.1\nnum_warmup_steps = int(total_steps * warmup_percentage)\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer, \n    num_warmup_steps=num_warmup_steps, \n    num_training_steps=total_steps\n)\n\nloss_fn = nn.CrossEntropyLoss()\n\n# Eğitim Fonksiyonu\ndef train_epoch(model, train_dataloader, optimizer, loss_fn, scheduler, device, progress_bar=None):\n    model.train()\n    total_loss = 0\n    \n    for batch in train_dataloader:\n        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        total_loss += loss.item()\n\n        if progress_bar:\n            progress_bar.update(1)\n    \n    avg_loss = total_loss / len(train_dataloader)\n    return avg_loss\n\n# Değerlendirme Fonksiyonu\ndef eval_epoch(model, val_dataloader, loss_fn, device):\n    model.eval()\n    total_loss = 0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for batch in val_dataloader:\n            input_ids, attention_mask, labels = [x.to(device) for x in batch]\n            \n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            logits = outputs.logits\n\n            total_loss += loss.item()\n            preds = torch.argmax(logits, dim=1)\n            correct += (preds == labels).sum().item()\n            total += len(labels)\n\n    avg_loss = total_loss / len(val_dataloader)\n    accuracy = correct / total\n    return avg_loss, accuracy\n\n# Eğitim ve Değerlendirme\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nfor epoch in range(num_epochs):\n    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n\n    train_loss = 0\n    with tqdm(total=len(train_dataloader), desc=f\"Training Epoch {epoch + 1}\") as pbar:\n        train_loss = train_epoch(model, train_dataloader, optimizer, loss_fn, scheduler, device, pbar)\n\n    val_loss, val_accuracy = eval_epoch(model, val_dataloader, loss_fn, device)\n\n    print(f\"Training loss: {train_loss:.4f}\")\n    print(f\"Validation loss: {val_loss:.4f}, Validation accuracy: {val_accuracy:.4f}\")\n\n# Modeli Kaydetme\nmodel.save_pretrained(\"Electra_sentiment_Turkish_product_reviews\")\n\n# Modeli Yükleme\nmodel_loaded = ElectraForSequenceClassification.from_pretrained(\"Electra_sentiment_Turkish_product_reviews\")\nmodel_loaded.to(device)\n\n# Yeni Tahminler\ndef make_new_prediction(raw_review, model):\n    tokenized_review = tokenizer(\n        raw_review,\n        return_tensors='pt', \n        padding=True,\n        truncation=True,\n        max_length=65\n    )\n    \n    input_ids = tokenized_review['input_ids'].to(device)\n    attention_mask = tokenized_review['attention_mask'].to(device)\n    \n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n    \n    predicted_class = torch.argmax(logits, dim=1).item()\n\n    class_labels = {0: 'Negative', 1: 'Positive', 2: 'Neutral'}\n    predicted_label = class_labels[predicted_class]\n\n    print(\"Predicted class for the new review:\", predicted_label)\n    \n    return predicted_label\n\n# Örnek bir inceleme\nnew_review = \"guzel bir urundu, begendim, fiyati da gayet makul.\"\nmake_new_prediction(new_review, model_loaded)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-07T19:09:35.848960Z","iopub.execute_input":"2024-08-07T19:09:35.849326Z","iopub.status.idle":"2024-08-07T19:17:22.622108Z","shell.execute_reply.started":"2024-08-07T19:09:35.849288Z","shell.execute_reply":"2024-08-07T19:17:22.621197Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Tesla T4\nTesla T4\n(15170, 2)\n                                                   Metin  Durum\n1770   4 aydir kulkaniyorum sarji fazla yok dediler t...      1\n4487                                fiyatına göre guzel.      1\n9720                Harika bir oyun çocukluğumuza döndük      1\n543    Ben ürünü daha önce berberde gördüm ve kulland...      1\n10667  30 martta aldım saati bugün kapandı açılmıyor ...      0\n(13569, 2)\nDurum\n0    0.477854\n1    0.427003\n2    0.095143\nName: proportion, dtype: float64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/126 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8657f93ea2394a8580742144785a8e5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/251k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b2726db06cd433d8766b0ce64f3479c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf05876a47b4483b8d12014dc736bf5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/789 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0150a532cc1840fcbec0b17f39113def"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a220ed60cd3e42cdb6df27b4b8481aa2"}},"metadata":{}},{"name":"stderr","text":"Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at kuzgunlar/electra-turkish-sentiment-analysis and are newly initialized because the shapes did not match:\n- classifier.out_proj.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([3, 768]) in the model instantiated\n- classifier.out_proj.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([3]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 1: 100%|██████████| 381/381 [02:09<00:00,  2.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training loss: 0.4001\nValidation loss: 0.2409, Validation accuracy: 0.9092\nEpoch 2/3\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 2: 100%|██████████| 381/381 [02:19<00:00,  2.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training loss: 0.1991\nValidation loss: 0.2265, Validation accuracy: 0.9137\nEpoch 3/3\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 3: 100%|██████████| 381/381 [02:20<00:00,  2.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training loss: 0.1497\nValidation loss: 0.2378, Validation accuracy: 0.9189\nPredicted class for the new review: Positive\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'Positive'"},"metadata":{}}]},{"cell_type":"code","source":"# Örnek bir inceleme\nnew_review = \"Turkcell'in bu kadar berbat bi interneti olamaz ya bu nedir abi hayatımda bu kadar saçma bir ürün görmedim .\"\nmake_new_prediction(new_review, model_loaded)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T19:18:36.022274Z","iopub.execute_input":"2024-08-07T19:18:36.022633Z","iopub.status.idle":"2024-08-07T19:18:36.050394Z","shell.execute_reply.started":"2024-08-07T19:18:36.022607Z","shell.execute_reply":"2024-08-07T19:18:36.049315Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Predicted class for the new review: Negative\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'Negative'"},"metadata":{}}]}]}